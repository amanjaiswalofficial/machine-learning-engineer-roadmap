{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parametric vs Non Parametric Learning\n",
    "\n",
    "Trial and error method \n",
    "**vs** \n",
    "Solve using counting, probability etc\n",
    "\n",
    "When no. of parameters are determined, just what setting/value they should be set at is to be identified \n",
    "**vs** \n",
    "Count based - keeps adding new parameters/settings as it finds something new to learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow of Parametric Learning:\n",
    "\n",
    "1. Use some data to predict\n",
    "2. Compare the output prediction to the truth\n",
    "3. Adjust the weights/values for the parameters, to predict better next time on similar data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(input, weight):\n",
    "    prediction = input * weight\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple inputs and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9700000000000001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def neural_network_2(input, weights):\n",
    "    prediction = w_sum(input, weights)\n",
    "    return prediction\n",
    "\n",
    "def w_sum(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    output = 0\n",
    "    for i in range(len(a)):\n",
    "        output += a[i] * b[i]\n",
    "\n",
    "    return output\n",
    "\n",
    "weights = [0.1, 0.2, 0]\n",
    "inputs = [8.5, 0.6, 1.2]\n",
    "\n",
    "pred = neural_network_2(inputs, weights)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple outputs and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.195, 0.13, 0.5850000000000001]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def neural_network_3(input, weights):\n",
    "    pred = ele_mul(input, weights)\n",
    "    return pred\n",
    "\n",
    "def ele_mul(number, vector):\n",
    "    output = [0, 0, 0]\n",
    "    assert len(output) == len(vector)\n",
    "    for i in range(len(vector)):\n",
    "        output[i] = number * vector[i]\n",
    "\n",
    "    return output\n",
    "\n",
    "weights = [0.3, 0.2, 0.9]\n",
    "win_loss_records = [0.65, 0.8, 0.8, 0.9]\n",
    "input = win_loss_records[0]\n",
    "pred = neural_network_3(input, weights)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple inputs and outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![](images\\img_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.555, 0.9800000000000001, 0.9650000000000001]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def neural_network_4(input, weights):\n",
    "    pred = vec_mat_mul(input, weights)\n",
    "    return pred\n",
    "\n",
    "def vec_mat_mul(vector, matrix):\n",
    "    output = [0] * len(vector)\n",
    "    for i in range(len(vector)):\n",
    "        output[i] = w_sum(vector, matrix[i])\n",
    "    \n",
    "    return output\n",
    "\n",
    "def w_sum(a, b):\n",
    "    assert(len(a) == len(b))\n",
    "    output = 0\n",
    "    for i in range(len(a)):\n",
    "        output += a[i] * b [i]\n",
    "    return output\n",
    "\n",
    "toes = [8.5, 9.5, 9.9, 9.0]\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "inputs = [toes[0], wlrec[0], nfans[0]]\n",
    "\n",
    "weights = [[0.1, 0.1, -0.3],[0.1, 0.2, 0.0], [0.0, 1.3, 0.1]]\n",
    "\n",
    "pred = neural_network_4(inputs, weights)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking predictions\n",
    "![](deep-learning\\images\\img_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.18849999999999997, 0.21000000000000002, 0.5065]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def neural_network_4(input, weights):\n",
    "    pred = vec_mat_mul(input, weights[0])\n",
    "    pred = vec_mat_mul(pred, weights[1])\n",
    "\n",
    "    return pred\n",
    "\n",
    "def vec_mat_mul(vector, matrix):\n",
    "    output = [0] * len(vector)\n",
    "    for i in range(len(vector)):\n",
    "        output[i] = w_sum(vector, matrix[i])\n",
    "    \n",
    "    return output\n",
    "\n",
    "def w_sum(a, b):\n",
    "    assert(len(a) == len(b))\n",
    "    output = 0\n",
    "    for i in range(len(a)):\n",
    "        output += a[i] * b [i]\n",
    "    return output\n",
    "\n",
    "toes = [8.5, 9.5, 9.9, 9.0]\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "inputs = [toes[0], wlrec[0], nfans[0]]\n",
    "\n",
    "weights_1 = [[0.1, 1.2, -0.1],[-0.1, 0.1, 0.9], [0.1, 0.4, 0.1]]\n",
    "weights_2 = [[0.1, 0.1, -0.3],[0.1, 0.2, 0.0], [0.0, 1.3, 0.1]]\n",
    "weights = [weights_1, weights_2]\n",
    "\n",
    "pred = neural_network_4(inputs, weights)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Same using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.915,  2.54 , -2.43 ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "weights_1 = np.array([[0.1, 1.2, -0.1],[-0.1, 0.1, 0.9], [0.1, 0.4, 0.1]])\n",
    "weights_2 = np.array([[0.1, 0.1, -0.3],[0.1, 0.2, 0.0], [0.0, 1.3, 0.1]])\n",
    "weights = [weights_1, weights_2]\n",
    "\n",
    "def neural_network(input, weights):\n",
    "    hid = input.dot(weights[0])\n",
    "    pred = input.dot(weights[1])\n",
    "    return pred\n",
    "\n",
    "toes = np.array([8.5])\n",
    "wlrec = np.array([0.65])\n",
    "nfans = np.array([1.2])\n",
    "\n",
    "input = np.array([toes[0], wlrec[0], nfans[0]])\n",
    "pred = neural_network(input, weights)\n",
    "pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare and Learn\n",
    "Post prediction, the next step is evaluation against actual result to tell how far was the prediction.\n",
    "\n",
    "##### Mean Squared Error (the compare part)\n",
    "One of the ways to do so is MSE. It tells whether the prediction was accurate, more by x amount, less by x amount.\n",
    "\n",
    "##### Gradient Descent (the learn part) \n",
    "GD fixes this by adjusting the weight\n",
    "1. Compare the number for each weight\n",
    "2. Move weight according to number\n",
    "3. Repeat if needed in next iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30250000000000005"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of measuring in python\n",
    "knob_weight = 0.5\n",
    "input = 0.5\n",
    "goal_pred = 0.8\n",
    "\n",
    "pred = input * knob_weight\n",
    "error = (pred - goal_pred)**2\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We square it because to avoid negative errors, as the difference can be -ve in some cases. Ex - in case of an archer, the arrow can be higher than the target, or lower than the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We measure error so that we can adjust the weights accordingly. The end goal in deep learning is to find weights such that the errors can be reduced to 0, and the prediction can be as close as the actuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Squaring the errors help prioritizing what weights to focus more on. error of 10 results in error of 1000, whereas error of 0.01 will result in 0.00001. As expected, working on the one with error 10 will yield more results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hot and Cold Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 1.0799505792475652e-27 Prediction 0.7999999999999672\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Running hot and cold learning\n",
    "weight = 0.5\n",
    "input = 0.5\n",
    "goal_prediction = 0.8\n",
    "step_amount = 0.001\n",
    "\n",
    "def neural_network(input, weight):\n",
    "    prediction = input * weight\n",
    "    return prediction\n",
    "\n",
    "for iter in range(1101):\n",
    "    prediction = neural_network(input, weight)\n",
    "    error = (prediction - goal_prediction) ** 2\n",
    "\n",
    "    up_pred = neural_network(input, weight + step_amount)\n",
    "    up_error = (goal_prediction - up_pred) ** 2\n",
    "\n",
    "    down_pred = neural_network(input, weight - step_amount)\n",
    "    down_error = (goal_prediction - down_pred) ** 2\n",
    "\n",
    "    if down_error < up_error:\n",
    "        weight = weight - step_amount\n",
    "    elif down_error > up_error:\n",
    "        weight = weight + step_amount\n",
    "\n",
    "print(\"Error\", error, \"Prediction\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way of doing Hot and Cold Learning is inefficient as it causes 3 times the prediction function to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent and using it to learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight 0\n",
      "Error 0.6400000000000001 Prediction 0.0\n",
      "Delta -0.8 Weight Delta -0.8800000000000001\n",
      "---\n",
      "Weight 0.8800000000000001\n",
      "Error 0.02822400000000005 Prediction 0.9680000000000002\n",
      "Delta 0.16800000000000015 Weight Delta 0.1848000000000002\n",
      "---\n",
      "Weight 0.6951999999999999\n",
      "Error 0.0012446784000000064 Prediction 0.76472\n",
      "Delta -0.03528000000000009 Weight Delta -0.0388080000000001\n",
      "---\n",
      "Weight 0.734008\n",
      "Error 5.4890317439999896e-05 Prediction 0.8074088\n",
      "Delta 0.007408799999999993 Weight Delta 0.008149679999999992\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "weight = 0\n",
    "input = 1.1\n",
    "goal_prediction = 0.8\n",
    "alpha = 1\n",
    "\n",
    "def neural_network(input, weight):\n",
    "    prediction = input * weight\n",
    "    return prediction\n",
    "\n",
    "for iter in range(4):\n",
    "    print(\"Weight\", weight)\n",
    "    prediction = neural_network(input, weight)\n",
    "    # square method\n",
    "    error = (prediction - goal_prediction) ** 2\n",
    "    # error = ((input*weight) - goal_prediction) ** 2\n",
    "    delta = prediction - goal_prediction\n",
    "    weight_delta = input * delta\n",
    "    weight -= weight_delta * alpha\n",
    "    print(\"Error\", error, \"Prediction\", prediction)\n",
    "    print(\"Delta\", delta, \"Weight Delta\", weight_delta)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this line states:\n",
    "```python\n",
    "error = ((input*weight) - goal_prediction) ** 2\n",
    "```\n",
    "If we fix the input and goal_prediction, which is something we are aware of from the beginning, then there's a direct relation between error and weight\n",
    "\n",
    "The goal hence is to have the weight adjusted in such a way that the error reaches the bottom of a bell curve.\n",
    "\n",
    "That would be the most optimal value of weight\n",
    "\n",
    "In above example, after 4 iterations. We reach the goal prediction, which is around 0.8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
